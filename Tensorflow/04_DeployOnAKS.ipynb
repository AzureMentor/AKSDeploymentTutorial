{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deploy Web App on Azure Container Services (AKS)\n",
    "In this notebook we will set up an Azure Container Service which will be managed by Kubernetes. We will then take the Docker image we created earlier that contains our app and deploy it to the ACS cluster. Then we will check everything is working by sending an image to it and getting it scored.\n",
    "\n",
    "The process is split into the following steps:\n",
    "* [Define our resource names](#section1)\n",
    "* [Login to Azure](#section2)\n",
    "* [Create the ACS](#section3)\n",
    "* [Create a tunnel to the head node](#section4)\n",
    "* [Create a JSON schema of our APP and push it to the cluster](#section5)\n",
    "* [Test our app](TestWebApp.ipynb)\n",
    "* [Tear it all down](#section7)\n",
    "\n",
    "This guide assumes is designed to be run on linux and requires that the Azure CLI is installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Below are the various name definitions for the resources needed to setup ACS as well as the name of the Docker image we will be using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some outputs (and inputs) below have been hidden/masked for confidentiality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Please modify the below as you see fit\n",
    "resource_group = \"<RESOURCE_GROUP>\" \n",
    "aks_name = \"<AKS_CLUSTER_NAME>\"\n",
    "location = \"eastus\"\n",
    "\n",
    "image_name = '<YOUR_DOCKER_IMAGE>' # 'masalvar/tfresnet-gpu' Feel free to use this Image if you want to \n",
    "                                   # skip creating your own container\n",
    "selected_subscription = \"'<YOUR SUBSCRIPTION>'\" # If you have multiple subscriptions select \n",
    "                                                # the subscription you want to use here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure account login\n",
    "The command below will initiate a login to your Azure account. It will pop up with an url to go to where you will enter a one off code and log into your Azure account using your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!az login -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!az account set --subscription $selected_subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!az account show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mRegistering is still on-going. You can monitor using 'az provider show -n Microsoft.ContainerService'\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!az provider register -n Microsoft.ContainerService"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create resources and dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create resource group\n",
    "Azure encourages the use of groups to organise all the Azure components you deploy. That way it is easier to find them but also we can deleted a number of resources simply by deleting the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/msaksrg\",\r\n",
      "  \"location\": \"eastus\",\r\n",
      "  \"managedBy\": null,\r\n",
      "  \"name\": \"msaksrg\",\r\n",
      "  \"properties\": {\r\n",
      "    \"provisioningState\": \"Succeeded\"\r\n",
      "  },\r\n",
      "  \"tags\": null\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az group create --name $resource_group --location $location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"additionalProperties\": {},\n",
      "  \"agentPoolProfiles\": [\n",
      "    {\n",
      "      \"additionalProperties\": {},\n",
      "      \"count\": 1,\n",
      "      \"dnsPrefix\": null,\n",
      "      \"fqdn\": null,\n",
      "      \"name\": \"nodepool1\",\n",
      "      \"osDiskSizeGb\": null,\n",
      "      \"osType\": \"Linux\",\n",
      "      \"ports\": null,\n",
      "      \"storageProfile\": \"ManagedDisks\",\n",
      "      \"vmSize\": \"Standard_NC6\",\n",
      "      \"vnetSubnetId\": null\n",
      "    }\n",
      "  ],\n",
      "  \"dnsPrefix\": \"msAKSTFClu-msaksrg-edf507\",\n",
      "  \"fqdn\": \"msakstfclu-msaksrg-edf507-1f197d36.hcp.eastus.azmk8s.io\",\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourcegroups/msaksrg/providers/Microsoft.ContainerService/managedClusters/msAKSTFCluster\",\n",
      "  \"kubernetesVersion\": \"1.7.9\",\n",
      "  \"linuxProfile\": {\n",
      "    \"additionalProperties\": {},\n",
      "    \"adminUsername\": \"azureuser\",\n",
      "    \"ssh\": {\n",
      "      \"additionalProperties\": {},\n",
      "      \"publicKeys\": [\n",
      "        {\n",
      "          \"additionalProperties\": {},\n",
      "          \"keyData\": \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDVfKBWPBKS84wluD3DJ0t3hepO2F13pz1VI5d4c7Tn4d80rSKJkF2L2HtAf3w9R7TM5TYcSlMqv+OFtB5iwfMk1k8sarGqmB1aLuEYBD60cqtdWD34DPWz8Y4eQ7x8eQ2joVRgMFpv+SfEuPBaQdTM7QtFiWRA1ZioXElyniL2Snhsd/ICcq5SIcZSPj3z9/eUcKGz/eImLkOYU28l8fLpVg48x70rGOtpfmDmZJ3KT/LImDWbPFF4VIRuiki4qVaMvDvwlEB7BmqM5D8qO7tOM3ncZ3TqUhrSQj9NbeC65xvB83+BiZts63VXAsMLnu+0wbAXnA4W66ly/5UyjC//\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"location\": \"eastus\",\n",
      "  \"name\": \"msAKSTFCluster\",\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"msaksrg\",\n",
      "  \"servicePrincipalProfile\": {\n",
      "    \"additionalProperties\": {},\n",
      "    \"clientId\": \"44ba57c3-4386-4788-a761-8d72faa493e2\",\n",
      "    \"keyVaultSecretRef\": null,\n",
      "    \"secret\": null\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.ContainerService/ManagedClusters\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az aks create --resource-group $resource_group --name $aks_name --node-count 1 --generate-ssh-keys -s Standard_NC6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install cli from comamnd prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDownloading client to /usr/local/bin/kubectl from https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl\u001b[0m\n",
      "\u001b[33mPlease ensure that /usr/local/bin is in your search PATH, so the `kubectl` command can be found.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo az aks install-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define our manifest file for our service and load balancer. Note that we have to specify the volume mounts to the drivers that are located on the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_template = {\n",
    "  \"apiVersion\": \"apps/v1beta1\",\n",
    "  \"kind\": \"Deployment\",\n",
    "  \"metadata\": {\n",
    "      \"name\": \"azure-dl\"\n",
    "  },\n",
    "  \"spec\":{\n",
    "      \"replicas\":1,\n",
    "      \"template\":{\n",
    "          \"metadata\":{\n",
    "              \"labels\":{\n",
    "                  \"app\":\"azure-dl\"\n",
    "              }\n",
    "          },\n",
    "          \"spec\":{\n",
    "              \"containers\":[\n",
    "                  {\n",
    "                      \"name\": \"azure-dl\",\n",
    "                      \"image\": \"masalvar/tfresnet-gpu\",\n",
    "                      \"env\":[\n",
    "                          {\n",
    "                              \"name\": \"LD_LIBRARY_PATH\",\n",
    "                              \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\"\n",
    "                          }\n",
    "                      ],\n",
    "                      \"ports\":[\n",
    "                          {\n",
    "                              \"containerPort\":80,\n",
    "                              \"name\":\"model\"\n",
    "                          }\n",
    "                      ],\n",
    "                      \"volumeMounts\":[\n",
    "                          {\n",
    "                            \"mountPath\": \"/usr/local/nvidia\",\n",
    "                            \"name\": \"nvidia\"\n",
    "                          }\n",
    "                      ],\n",
    "                      \"resources\":{\n",
    "                           \"requests\":{\n",
    "                               \"alpha.kubernetes.io/nvidia-gpu\": 1\n",
    "                           },\n",
    "                           \"limits\":{\n",
    "                               \"alpha.kubernetes.io/nvidia-gpu\": 1\n",
    "                           }\n",
    "                       }  \n",
    "                  }\n",
    "              ],\n",
    "              \"volumes\":[\n",
    "                  {\n",
    "                      \"name\": \"nvidia\",\n",
    "                      \"hostPath\":{\n",
    "                          \"path\":\"/usr/local/nvidia\"\n",
    "                      },\n",
    "                  },\n",
    "              ]\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "service_temp = {\n",
    "  \"apiVersion\": \"v1\",\n",
    "  \"kind\": \"Service\",\n",
    "  \"metadata\": {\n",
    "      \"name\": \"azure-dl\"\n",
    "  },\n",
    "  \"spec\":{\n",
    "      \"type\": \"LoadBalancer\",\n",
    "      \"ports\":[\n",
    "          {\n",
    "              \"port\":80\n",
    "          }\n",
    "      ],\n",
    "      \"selector\":{\n",
    "            \"app\":\"azure-dl\"\n",
    "      }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_json_to_file(json_dict, filename, mode='w'):\n",
    "    with open(filename, mode) as outfile:\n",
    "        json.dump(json_dict, outfile, indent=4,sort_keys=True)\n",
    "        outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_json_to_file(app_template, 'az-dl.json') # We write the service template to the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_json_to_file(service_temp, 'az-dl.json', mode='a') # We add the loadbelanacer template to the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"apiVersion\": \"apps/v1beta1\",\r\n",
      "    \"kind\": \"Deployment\",\r\n",
      "    \"metadata\": {\r\n",
      "        \"name\": \"azure-dl\"\r\n",
      "    },\r\n",
      "    \"spec\": {\r\n",
      "        \"replicas\": 1,\r\n",
      "        \"template\": {\r\n",
      "            \"metadata\": {\r\n",
      "                \"labels\": {\r\n",
      "                    \"app\": \"azure-dl\"\r\n",
      "                }\r\n",
      "            },\r\n",
      "            \"spec\": {\r\n",
      "                \"containers\": [\r\n",
      "                    {\r\n",
      "                        \"env\": [\r\n",
      "                            {\r\n",
      "                                \"name\": \"LD_LIBRARY_PATH\",\r\n",
      "                                \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\"\r\n",
      "                            }\r\n",
      "                        ],\r\n",
      "                        \"image\": \"masalvar/tfresnet-gpu\",\r\n",
      "                        \"name\": \"azure-dl\",\r\n",
      "                        \"ports\": [\r\n",
      "                            {\r\n",
      "                                \"containerPort\": 80,\r\n",
      "                                \"name\": \"model\"\r\n",
      "                            }\r\n",
      "                        ],\r\n",
      "                        \"resources\": {\r\n",
      "                            \"limits\": {\r\n",
      "                                \"alpha.kubernetes.io/nvidia-gpu\": 1\r\n",
      "                            },\r\n",
      "                            \"requests\": {\r\n",
      "                                \"alpha.kubernetes.io/nvidia-gpu\": 1\r\n",
      "                            }\r\n",
      "                        },\r\n",
      "                        \"volumeMounts\": [\r\n",
      "                            {\r\n",
      "                                \"mountPath\": \"/usr/local/nvidia\",\r\n",
      "                                \"name\": \"nvidia\"\r\n",
      "                            }\r\n",
      "                        ]\r\n",
      "                    }\r\n",
      "                ],\r\n",
      "                \"volumes\": [\r\n",
      "                    {\r\n",
      "                        \"hostPath\": {\r\n",
      "                            \"path\": \"/usr/local/nvidia\"\r\n",
      "                        },\r\n",
      "                        \"name\": \"nvidia\"\r\n",
      "                    }\r\n",
      "                ]\r\n",
      "            }\r\n",
      "        }\r\n",
      "    }\r\n",
      "}\r\n",
      "\r\n",
      "{\r\n",
      "    \"apiVersion\": \"v1\",\r\n",
      "    \"kind\": \"Service\",\r\n",
      "    \"metadata\": {\r\n",
      "        \"name\": \"azure-dl\"\r\n",
      "    },\r\n",
      "    \"spec\": {\r\n",
      "        \"ports\": [\r\n",
      "            {\r\n",
      "                \"port\": 80\r\n",
      "            }\r\n",
      "        ],\r\n",
      "        \"selector\": {\r\n",
      "            \"app\": \"azure-dl\"\r\n",
      "        },\r\n",
      "        \"type\": \"LoadBalancer\"\r\n",
      "    }\r\n",
      "}\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat az-dl.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged \"msAKSTFCluster\" as current context in /home/mat/.kube/config\r\n"
     ]
    }
   ],
   "source": [
    "!az aks get-credentials --resource-group=$resource_group --name=$aks_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       STATUS    ROLES     AGE       VERSION\r\n",
      "aks-nodepool1-27496346-0   Ready     agent     2m        v1.7.9\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE\r\n",
      "kube-system   heapster-2574232661-07lzh               2/2       Running   0          1m\r\n",
      "kube-system   kube-dns-v20-2253765213-730n6           3/3       Running   0          2m\r\n",
      "kube-system   kube-dns-v20-2253765213-m9d9q           3/3       Running   0          2m\r\n",
      "kube-system   kube-proxy-3d25d                        1/1       Running   0          2m\r\n",
      "kube-system   kube-svc-redirect-psp3n                 1/1       Running   0          2m\r\n",
      "kube-system   kubernetes-dashboard-2898242510-7h28r   1/1       Running   0          2m\r\n",
      "kube-system   tunnelfront-527646831-lj63z             1/1       Running   0          2m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will create everything we specified in the az-dl.json manifest file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"azure-dl\" created\n",
      "service \"azure-dl\" created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f az-dl.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds you should see the pod start running on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE\r\n",
      "default       azure-dl-3880299103-v5mb7               1/1       Running   0          4m\r\n",
      "kube-system   heapster-2574232661-07lzh               2/2       Running   0          5m\r\n",
      "kube-system   kube-dns-v20-2253765213-730n6           3/3       Running   0          6m\r\n",
      "kube-system   kube-dns-v20-2253765213-m9d9q           3/3       Running   0          6m\r\n",
      "kube-system   kube-proxy-3d25d                        1/1       Running   0          6m\r\n",
      "kube-system   kube-svc-redirect-psp3n                 1/1       Running   0          6m\r\n",
      "kube-system   kubernetes-dashboard-2898242510-7h28r   1/1       Running   0          6m\r\n",
      "kube-system   tunnelfront-527646831-lj63z             1/1       Running   0          6m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anything goes wrong you can use the commands below to observe the events on the node as well as review the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST SEEN   FIRST SEEN   COUNT     NAME                                         KIND         SUBOBJECT                   TYPE      REASON                             SOURCE                                 MESSAGE\r\n",
      "9m          9m           1         aks-nodepool1-27496346-0.1520fb005972710f    Node                                     Normal    Starting                           kubelet, aks-nodepool1-27496346-0      Starting kubelet.\r\n",
      "7m          8m           3         aks-nodepool1-27496346-0.1520fb08e765af3d    Node                                     Normal    NodeHasSufficientDisk              kubelet, aks-nodepool1-27496346-0      Node aks-nodepool1-27496346-0 status is now: NodeHasSufficientDisk\r\n",
      "7m          8m           3         aks-nodepool1-27496346-0.1520fb08e7663219    Node                                     Normal    NodeHasSufficientMemory            kubelet, aks-nodepool1-27496346-0      Node aks-nodepool1-27496346-0 status is now: NodeHasSufficientMemory\r\n",
      "7m          8m           3         aks-nodepool1-27496346-0.1520fb08e7665b1e    Node                                     Normal    NodeHasNoDiskPressure              kubelet, aks-nodepool1-27496346-0      Node aks-nodepool1-27496346-0 status is now: NodeHasNoDiskPressure\r\n",
      "55s         8m           9         aks-nodepool1-27496346-0.1520fb08e780a4eb    Node                                     Warning   FailedNodeAllocatableEnforcement   kubelet, aks-nodepool1-27496346-0      Failed to update Node Allocatable Limits \"\": failed to set supported cgroup subsystems for cgroup : Failed to set config for supported subsystems : failed to write 59076296704 to memory.limit_in_bytes: write /var/lib/docker/overlay2/daad1bc683430e39749de19537b2702c53db1f36ba866537b8f76687375c368f/merged/sys/fs/cgroup/memory/memory.limit_in_bytes: invalid argument\r\n",
      "6m          6m           1         aks-nodepool1-27496346-0.1520fb2740f627b6    Node                                     Normal    RegisteredNode                     controllermanager                      Node aks-nodepool1-27496346-0 event: Registered Node aks-nodepool1-27496346-0 in NodeController\r\n",
      "6m          6m           1         aks-nodepool1-27496346-0.1520fb29877c82d1    Node                                     Normal    Starting                           kube-proxy, aks-nodepool1-27496346-0   Starting kube-proxy.\r\n",
      "6m          6m           1         aks-nodepool1-27496346-0.1520fb2d38a1c12c    Node                                     Normal    NodeReady                          kubelet, aks-nodepool1-27496346-0      Node aks-nodepool1-27496346-0 status is now: NodeReady\r\n",
      "4m          4m           1         azure-dl-3880299103-v5mb7.1520fb46d4fdc9fa   Pod                                      Normal    Scheduled                          default-scheduler                      Successfully assigned azure-dl-3880299103-v5mb7 to aks-nodepool1-27496346-0\r\n",
      "4m          4m           1         azure-dl-3880299103-v5mb7.1520fb46e1cd117d   Pod                                      Normal    SuccessfulMountVolume              kubelet, aks-nodepool1-27496346-0      MountVolume.SetUp succeeded for volume \"bin\" \r\n",
      "4m          4m           1         azure-dl-3880299103-v5mb7.1520fb46e1cf3b05   Pod                                      Normal    SuccessfulMountVolume              kubelet, aks-nodepool1-27496346-0      MountVolume.SetUp succeeded for volume \"libcuda\" \r\n",
      "4m          4m           1         azure-dl-3880299103-v5mb7.1520fb46e1cf86ce   Pod                                      Normal    SuccessfulMountVolume              kubelet, aks-nodepool1-27496346-0      MountVolume.SetUp succeeded for volume \"lib\" \r\n",
      "4m          4m           1         azure-dl-3880299103-v5mb7.1520fb46e2516335   Pod                                      Normal    SuccessfulMountVolume              kubelet, aks-nodepool1-27496346-0      MountVolume.SetUp succeeded for volume \"default-token-thxzk\" \r\n",
      "4m          4m           1         azure-dl-3880299103-v5mb7.1520fb47102b3c32   Pod          spec.containers{azure-dl}   Normal    Pulling                            kubelet, aks-nodepool1-27496346-0      pulling image \"masalvar/tfresnet-gpu\"\r\n",
      "1m          1m           1         azure-dl-3880299103-v5mb7.1520fb73ea97742a   Pod          spec.containers{azure-dl}   Normal    Pulled                             kubelet, aks-nodepool1-27496346-0      Successfully pulled image \"masalvar/tfresnet-gpu\"\r\n",
      "1m          1m           1         azure-dl-3880299103-v5mb7.1520fb75bccdb1f5   Pod          spec.containers{azure-dl}   Normal    Created                            kubelet, aks-nodepool1-27496346-0      Created container\r\n",
      "1m          1m           1         azure-dl-3880299103-v5mb7.1520fb76711f3dd5   Pod          spec.containers{azure-dl}   Normal    Started                            kubelet, aks-nodepool1-27496346-0      Started container\r\n",
      "4m          4m           1         azure-dl-3880299103.1520fb46d46b36d8         ReplicaSet                               Normal    SuccessfulCreate                   replicaset-controller                  Created pod: azure-dl-3880299103-v5mb7\r\n",
      "4m          4m           1         azure-dl.1520fb46d294f3d3                    Deployment                               Normal    ScalingReplicaSet                  deployment-controller                  Scaled up replica set azure-dl-3880299103 to 1\r\n",
      "4m          4m           1         azure-dl.1520fb46d8ebdb8a                    Service                                  Normal    CreatingLoadBalancer               service-controller                     Creating load balancer\r\n",
      "2m          2m           1         azure-dl.1520fb66b2965ba7                    Service                                  Normal    CreatedLoadBalancer                service-controller                     Created load balancer\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-31 10:45:57,344 CRIT Supervisor running as root (no user in config file)\r\n",
      "2018-03-31 10:45:57,346 INFO supervisord started with pid 7\r\n",
      "2018-03-31 10:45:58,348 INFO spawned: 'program_exit' with pid 15\r\n",
      "2018-03-31 10:45:58,349 INFO spawned: 'nginx' with pid 16\r\n",
      "2018-03-31 10:45:58,351 INFO spawned: 'gunicorn' with pid 17\r\n",
      "2018-03-31 10:45:59,380 INFO success: program_exit entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\r\n",
      "2018-03-31 10:45:59.971916: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n",
      "2018-03-31 10:46:03,977 INFO success: nginx entered RUNNING state, process has stayed up for > than 5 seconds (startsecs)\r\n",
      "2018-03-31 10:46:11.453255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: \r\n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\n",
      "pciBusID: cff2:00:00.0\r\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\r\n",
      "2018-03-31 10:46:11.453299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: cff2:00:00.0, compute capability: 3.7)\r\n",
      "INFO:tensorflow:Restoring parameters from resnet_v1_152.ckpt\r\n",
      "{\"timestamp\": \"2018-03-31T10:46:17.203847Z\", \"level\": \"INFO\", \"stack_info\": null, \"host\": \"azure-dl-3880299103-v5mb7\", \"message\": \"Restoring parameters from resnet_v1_152.ckpt\", \"logger\": \"tensorflow\", \"msg\": \"Restoring parameters from %s\", \"tags\": [], \"path\": \"/opt/conda/envs/py3.5/lib/python3.5/site-packages/tensorflow/python/platform/tf_logging.py\"}\r\n",
      "{\"timestamp\": \"2018-03-31T10:46:19.060001Z\", \"level\": \"INFO\", \"stack_info\": null, \"host\": \"azure-dl-3880299103-v5mb7\", \"message\": \"Model loading time: 19089.38 ms\", \"logger\": \"model_driver\", \"tags\": [], \"path\": \"/code/driver.py\"}\r\n",
      "2018-03-31 10:46:19,060 INFO success: gunicorn entered RUNNING state, process has stayed up for > than 20 seconds (startsecs)\r\n",
      "Initialising\r\n",
      "{\"timestamp\": \"2018-03-31T10:46:19.065300Z\", \"level\": \"INFO\", \"stack_info\": null, \"host\": \"azure-dl-3880299103-v5mb7\", \"message\": \" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\", \"logger\": \"werkzeug\", \"msg\": \" * Running on %s://%s:%d/ %s\", \"tags\": [], \"path\": \"/opt/conda/envs/py3.5/lib/python3.5/site-packages/werkzeug/_internal.py\"}\r\n"
     ]
    }
   ],
   "source": [
    "pod_json = !kubectl get pods -o json\n",
    "pod_dict = json.loads(''.join(pod_json))\n",
    "!kubectl logs {pod_dict['items'][0]['metadata']['name']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can take a few minutes for the service to populate the EXTERNAL-IP field. This will be the IP you use to call the service. You can also specify an IP to use please see the AKS documentation for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME       TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)        AGE\r\n",
      "azure-dl   LoadBalancer   10.0.204.221   40.71.172.160   80:32567/TCP   11m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get service azure-dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our deployed service we can move onto [testing it](05_TestWebApp.ipynb)  \n",
    "Below are the instructions to tear everything down once we are done with the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='section7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tear it all down \n",
    "Once you are done with your cluster you can use the following two commands to destroy it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment \"azure-dl\" deleted\n",
      "service \"azure-dl\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f az-dl.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished .."
     ]
    }
   ],
   "source": [
    "!az aks delete -n $aks_name -g $resource_group -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished .."
     ]
    }
   ],
   "source": [
    "!az group delete --name $resource_group -y"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
